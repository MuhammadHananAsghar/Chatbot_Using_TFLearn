{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chatbot Using TFLearn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsU3zDkq0_hD"
      },
      "source": [
        "**Implemented By Muhammad Hanan Asghar**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ayE3ZvKls19"
      },
      "source": [
        "# Libraries needed for NLP\n",
        "import nltk\n",
        "nltk.download('punkt') # This Package is used to convert sentences to individual words\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "stemmer = LancasterStemmer()\n",
        "\n",
        "# LancasterStemmer reduces the words by Making all to the root word\n",
        "# Example: waiting, waited, waits are converted to root word 'wait'\n",
        "# Example: cooker, cooks, cooked , cooking converted to root word 'cook'\n",
        "\n",
        "!pip install tflearn\n",
        "!pip install tensorflow\n",
        "!pip install numpy\n",
        "\n",
        "# Libraries needed for Tensorflow processing\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tflearn\n",
        "import random\n",
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "id": "amDTCbHpmOX5",
        "outputId": "7f23d493-271d-42bf-fcca-091740e1a405"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-17558a03-09d6-4e50-b268-fbc25b0489d1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-17558a03-09d6-4e50-b268-fbc25b0489d1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving intents.json to intents.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'intents.json': b'{\"intents\": [\\n        {\"tag\": \"greeting\",\\n         \"patterns\": [\"Hi there\", \"How are you\", \"Is anyone there?\",\"Hey\",\"Hola\", \"Hello\", \"Good day\"],\\n         \"responses\": [\"Hello, thanks for asking\", \"Good to see you again\", \"Hi there, how can I help?\"],\\n         \"context\": [\"\"]\\n        },\\n        {\"tag\": \"goodbye\",\\n         \"patterns\": [\"Bye\", \"See you later\", \"Goodbye\", \"Nice chatting to you, bye\", \"Till next time\"],\\n         \"responses\": [\"See you!\", \"Have a nice day\", \"Bye! Come back again soon.\"],\\n         \"context\": [\"\"]\\n        },\\n        {\"tag\": \"thanks\",\\n         \"patterns\": [\"Thanks\", \"Thank you\", \"That\\'s helpful\", \"Awesome, thanks\", \"Thanks for helping me\"],\\n         \"responses\": [\"Happy to help!\", \"Any time!\", \"My pleasure\"],\\n         \"context\": [\"\"]\\n        },\\n        {\"tag\": \"noanswer\",\\n         \"patterns\": [],\\n         \"responses\": [\"Sorry, can\\'t understand you\", \"Please give me more info\", \"Not sure I understand\"],\\n         \"context\": [\"\"]\\n        },\\n        {\"tag\": \"options\",\\n         \"patterns\": [\"How you could help me?\", \"What you can do?\", \"What help you provide?\", \"How you can be helpful?\", \"What support is offered\"],\\n         \"responses\": [\"I can guide you through Adverse drug reaction list, Blood pressure tracking, Hospitals and Pharmacies\", \"Offering support for Adverse drug reaction, Blood pressure, Hospitals and Pharmacies\"],\\n         \"context\": [\"\"]\\n        },\\n        {\"tag\": \"adverse_drug\",\\n         \"patterns\": [\"How to check Adverse drug reaction?\", \"Open adverse drugs module\", \"Give me a list of drugs causing adverse behavior\", \"List all drugs suitable for patient with adverse reaction\", \"Which drugs dont have adverse reaction?\" ],\\n         \"responses\": [\"Navigating to Adverse drug reaction module\"],\\n         \"context\": [\"\"]\\n        },\\n        {\"tag\": \"blood_pressure\",\\n         \"patterns\": [\"Open blood pressure module\", \"Task related to blood pressure\", \"Blood pressure data entry\", \"I want to log blood pressure results\", \"Blood pressure data management\" ],\\n         \"responses\": [\"Navigating to Blood Pressure module\"],\\n         \"context\": [\"\"]\\n        },\\n        {\"tag\": \"blood_pressure_search\",\\n         \"patterns\": [\"I want to search for blood pressure result history\", \"Blood pressure for patient\", \"Load patient blood pressure result\", \"Show blood pressure results for patient\", \"Find blood pressure results by ID\" ],\\n         \"responses\": [\"Please provide Patient ID\", \"Patient ID?\"],\\n         \"context\": [\"search_blood_pressure_by_patient_id\"]\\n        },\\n        {\"tag\": \"search_blood_pressure_by_patient_id\",\\n         \"patterns\": [],\\n         \"responses\": [\"Loading Blood pressure result for Patient\"],\\n         \"context\": [\"\"]\\n        },\\n        {\"tag\": \"pharmacy_search\",\\n         \"patterns\": [\"Find me a pharmacy\", \"Find pharmacy\", \"List of pharmacies nearby\", \"Locate pharmacy\", \"Search pharmacy\" ],\\n         \"responses\": [\"Please provide pharmacy name\"],\\n         \"context\": [\"search_pharmacy_by_name\"]\\n        },\\n        {\"tag\": \"search_pharmacy_by_name\",\\n         \"patterns\": [],\\n         \"responses\": [\"Loading pharmacy details\"],\\n         \"context\": [\"\"]\\n        },\\n        {\"tag\": \"hospital_search\",\\n         \"patterns\": [\"Lookup for hospital\", \"Searching for hospital to transfer patient\", \"I want to search hospital data\", \"Hospital lookup for patient\", \"Looking up hospital details\" ],\\n         \"responses\": [\"Please provide hospital name or location\"],\\n         \"context\": [\"search_hospital_by_params\"]\\n        },\\n        {\"tag\": \"search_hospital_by_params\",\\n         \"patterns\": [],\\n         \"responses\": [\"Please provide hospital type\"],\\n         \"context\": [\"search_hospital_by_type\"]\\n        },\\n        {\"tag\": \"search_hospital_by_type\",\\n         \"patterns\": [],\\n         \"responses\": [\"Loading hospital details\"],\\n         \"context\": [\"\"]\\n        }\\n   ]\\n}\\n'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39aXmk1OnAnJ"
      },
      "source": [
        "# import our chat-bot intents file\n",
        "with open('intents.json') as json_data:\n",
        "    intents = json.load(json_data)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHbuLqOLnFeZ",
        "outputId": "ba701415-d8d7-4327-c3b0-956901bee1fd"
      },
      "source": [
        "intents"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'intents': [{'context': [''],\n",
              "   'patterns': ['Hi there',\n",
              "    'How are you',\n",
              "    'Is anyone there?',\n",
              "    'Hey',\n",
              "    'Hola',\n",
              "    'Hello',\n",
              "    'Good day'],\n",
              "   'responses': ['Hello, thanks for asking',\n",
              "    'Good to see you again',\n",
              "    'Hi there, how can I help?'],\n",
              "   'tag': 'greeting'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['Bye',\n",
              "    'See you later',\n",
              "    'Goodbye',\n",
              "    'Nice chatting to you, bye',\n",
              "    'Till next time'],\n",
              "   'responses': ['See you!', 'Have a nice day', 'Bye! Come back again soon.'],\n",
              "   'tag': 'goodbye'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['Thanks',\n",
              "    'Thank you',\n",
              "    \"That's helpful\",\n",
              "    'Awesome, thanks',\n",
              "    'Thanks for helping me'],\n",
              "   'responses': ['Happy to help!', 'Any time!', 'My pleasure'],\n",
              "   'tag': 'thanks'},\n",
              "  {'context': [''],\n",
              "   'patterns': [],\n",
              "   'responses': [\"Sorry, can't understand you\",\n",
              "    'Please give me more info',\n",
              "    'Not sure I understand'],\n",
              "   'tag': 'noanswer'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['How you could help me?',\n",
              "    'What you can do?',\n",
              "    'What help you provide?',\n",
              "    'How you can be helpful?',\n",
              "    'What support is offered'],\n",
              "   'responses': ['I can guide you through Adverse drug reaction list, Blood pressure tracking, Hospitals and Pharmacies',\n",
              "    'Offering support for Adverse drug reaction, Blood pressure, Hospitals and Pharmacies'],\n",
              "   'tag': 'options'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['How to check Adverse drug reaction?',\n",
              "    'Open adverse drugs module',\n",
              "    'Give me a list of drugs causing adverse behavior',\n",
              "    'List all drugs suitable for patient with adverse reaction',\n",
              "    'Which drugs dont have adverse reaction?'],\n",
              "   'responses': ['Navigating to Adverse drug reaction module'],\n",
              "   'tag': 'adverse_drug'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['Open blood pressure module',\n",
              "    'Task related to blood pressure',\n",
              "    'Blood pressure data entry',\n",
              "    'I want to log blood pressure results',\n",
              "    'Blood pressure data management'],\n",
              "   'responses': ['Navigating to Blood Pressure module'],\n",
              "   'tag': 'blood_pressure'},\n",
              "  {'context': ['search_blood_pressure_by_patient_id'],\n",
              "   'patterns': ['I want to search for blood pressure result history',\n",
              "    'Blood pressure for patient',\n",
              "    'Load patient blood pressure result',\n",
              "    'Show blood pressure results for patient',\n",
              "    'Find blood pressure results by ID'],\n",
              "   'responses': ['Please provide Patient ID', 'Patient ID?'],\n",
              "   'tag': 'blood_pressure_search'},\n",
              "  {'context': [''],\n",
              "   'patterns': [],\n",
              "   'responses': ['Loading Blood pressure result for Patient'],\n",
              "   'tag': 'search_blood_pressure_by_patient_id'},\n",
              "  {'context': ['search_pharmacy_by_name'],\n",
              "   'patterns': ['Find me a pharmacy',\n",
              "    'Find pharmacy',\n",
              "    'List of pharmacies nearby',\n",
              "    'Locate pharmacy',\n",
              "    'Search pharmacy'],\n",
              "   'responses': ['Please provide pharmacy name'],\n",
              "   'tag': 'pharmacy_search'},\n",
              "  {'context': [''],\n",
              "   'patterns': [],\n",
              "   'responses': ['Loading pharmacy details'],\n",
              "   'tag': 'search_pharmacy_by_name'},\n",
              "  {'context': ['search_hospital_by_params'],\n",
              "   'patterns': ['Lookup for hospital',\n",
              "    'Searching for hospital to transfer patient',\n",
              "    'I want to search hospital data',\n",
              "    'Hospital lookup for patient',\n",
              "    'Looking up hospital details'],\n",
              "   'responses': ['Please provide hospital name or location'],\n",
              "   'tag': 'hospital_search'},\n",
              "  {'context': ['search_hospital_by_type'],\n",
              "   'patterns': [],\n",
              "   'responses': ['Please provide hospital type'],\n",
              "   'tag': 'search_hospital_by_params'},\n",
              "  {'context': [''],\n",
              "   'patterns': [],\n",
              "   'responses': ['Loading hospital details'],\n",
              "   'tag': 'search_hospital_by_type'}]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-1t92PxnePh"
      },
      "source": [
        "words = []\n",
        "classes = []\n",
        "documents = []\n",
        "ignore = ['?']\n",
        "# loop through each sentence in the intent's patterns\n",
        "for intent in intents['intents']:\n",
        "    for pattern in intent['patterns']:\n",
        "        # tokenize each and every word in the sentence\n",
        "        w = nltk.word_tokenize(pattern)\n",
        "        # add word to the words list\n",
        "        words.extend(w)\n",
        "        # add word(s) to documents\n",
        "        documents.append((w, intent['tag']))\n",
        "        # add tags to our classes list\n",
        "        if intent['tag'] not in classes:\n",
        "            classes.append(intent['tag'])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uo3Im13FnqX4",
        "outputId": "59c6cee3-2184-4f0e-c393-bfed07ceb800"
      },
      "source": [
        "words[:5] # This is Called Tokenization"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hi', 'there', 'How', 'are', 'you']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9LK_kKVnrlC",
        "outputId": "aab977ae-e942-4b9f-a619-7f7c0ced2ccd"
      },
      "source": [
        "documents[:5] # This is called Document Making in Chatbot Building."
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(['Hi', 'there'], 'greeting'),\n",
              " (['How', 'are', 'you'], 'greeting'),\n",
              " (['Is', 'anyone', 'there', '?'], 'greeting'),\n",
              " (['Hey'], 'greeting'),\n",
              " (['Hola'], 'greeting')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKW2_94wnydk",
        "outputId": "385492ac-7e33-4059-a0ec-88ce65a9ac0c"
      },
      "source": [
        "classes[:5] #This is called class seperating."
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['greeting', 'goodbye', 'thanks', 'options', 'adverse_drug']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvDT_Oj4oExI"
      },
      "source": [
        "# Converting each word to their root word\n",
        "__words = []\n",
        "for word in words:\n",
        "  if word not in ignore:\n",
        "    __w = stemmer.stem(word)\n",
        "    __words.append(__w.lower())"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuobqbmaoeR6",
        "outputId": "55612607-bd1b-4825-d6b8-f6744c12ef50"
      },
      "source": [
        "__words[:5] # This is called Lancaster Stemming Alghorithum"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hi', 'ther', 'how', 'ar', 'you']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTDZdOecojct"
      },
      "source": [
        "# Let's Sort our __word list and removing duplicates\n",
        "__words = sorted(list(set(__words)))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bF1C-VNqo1jP",
        "outputId": "b53959ba-8c77-414f-cf82-2ba95da49e44"
      },
      "source": [
        "__words[:5]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"'s\", ',', 'a', 'advers', 'al']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOMTzPiWo4ke"
      },
      "source": [
        "# Removing Duplicates by using set\n",
        "classes = sorted(list(set(classes)))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtLafYzNpA4-",
        "outputId": "9120812d-370d-4fb3-ac34-46ec5c88e63b"
      },
      "source": [
        "classes[:5]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['adverse_drug',\n",
              " 'blood_pressure',\n",
              " 'blood_pressure_search',\n",
              " 'goodbye',\n",
              " 'greeting']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTFjvo6BpBuf",
        "outputId": "3d8d5c86-515a-449a-acf4-5c898de6008d"
      },
      "source": [
        "print (len(documents), \"Cocuments\")\n",
        "print (len(classes), \"Classes\", classes)\n",
        "print (len(__words), \"Unique Stemmed Words\", __words)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "47 Cocuments\n",
            "9 Classes ['adverse_drug', 'blood_pressure', 'blood_pressure_search', 'goodbye', 'greeting', 'hospital_search', 'options', 'pharmacy_search', 'thanks']\n",
            "84 Unique Stemmed Words [\"'s\", ',', 'a', 'advers', 'al', 'anyon', 'ar', 'awesom', 'be', 'behavy', 'blood', 'by', 'bye', 'can', 'caus', 'chat', 'check', 'could', 'dat', 'day', 'detail', 'do', 'dont', 'drug', 'entry', 'find', 'for', 'giv', 'good', 'goodby', 'hav', 'hello', 'help', 'hey', 'hi', 'hist', 'hol', 'hospit', 'how', 'i', 'id', 'is', 'lat', 'list', 'load', 'loc', 'log', 'look', 'lookup', 'man', 'me', 'mod', 'nearby', 'next', 'nic', 'of', 'off', 'op', 'paty', 'pharm', 'press', 'provid', 'react', 'rel', 'result', 'search', 'see', 'show', 'suit', 'support', 'task', 'thank', 'that', 'ther', 'til', 'tim', 'to', 'transf', 'up', 'want', 'what', 'which', 'with', 'you']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gc1PRSAMqcKy"
      },
      "source": [
        "#**Let's Convert our Preprocessed Data to Tensors**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KovhbOlJpJQQ"
      },
      "source": [
        "# create training data\n",
        "training = []\n",
        "output = []\n",
        "# create an empty array for output\n",
        "output_empty = [0] * len(classes)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QT2zKFNzqQMZ"
      },
      "source": [
        "# create training set, bag of words for each sentence\n",
        "for doc in documents:\n",
        "  # initialize bag of words\n",
        "  bag = []\n",
        "  # list of tokenized words for the pattern\n",
        "  pattern_words = doc[0]\n",
        "  # Stemming Our Doc Words\n",
        "  __patterns = [stemmer.stem(word.lower()) for word in pattern_words if word not in ignore]\n",
        "  # create bag of words array\n",
        "  for w in words:\n",
        "    bag.append(1) if w in __patterns else bag.append(0)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObsdF6mwqTmn",
        "outputId": "51c13948-08c6-46ae-9628-251d4e064db1"
      },
      "source": [
        "# create training set, bag of words for each sentence\n",
        "for doc in documents:\n",
        "  # initialize bag of words\n",
        "  bag = []\n",
        "  # list of tokenized words for the pattern\n",
        "  pattern_words = doc[0]\n",
        "  # Stemming Our Doc Words\n",
        "  __patterns = [stemmer.stem(word.lower()) for word in pattern_words if word not in ignore]\n",
        "  # create bag of words array\n",
        "  for w in words:\n",
        "    bag.append(1) if w in __patterns else bag.append(0)\n",
        "  # output is '1' for current tag and '0' for rest of other tags\n",
        "  output_row = list(output_empty)\n",
        "  print(output_row)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuzOMG3Gr0YY",
        "outputId": "7cece02e-9363-402f-c8af-840e5ffd041f"
      },
      "source": [
        " # create training set, bag of words for each sentence\n",
        "for doc in documents:\n",
        "  # initialize bag of words\n",
        "  bag = []\n",
        "  # list of tokenized words for the pattern\n",
        "  pattern_words = doc[0]\n",
        "  # Stemming Our Doc Words\n",
        "  __patterns = [stemmer.stem(word.lower()) for word in pattern_words if word not in ignore]\n",
        "  # create bag of words array\n",
        "  for w in words:\n",
        "    bag.append(1) if w in __patterns else bag.append(0)\n",
        "  # output is '1' for current tag and '0' for rest of other tags\n",
        "  output_row = list(output_empty)\n",
        "  # Here i am making target list for fully connected layer in Neural Network\n",
        "  output_row[classes.index(doc[1])] = 1\n",
        "  print(output_row)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "[0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "[0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "[1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "[0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 1, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kK_BoA1jsD5o"
      },
      "source": [
        " # create training set, bag of words for each sentence\n",
        "for doc in documents:\n",
        "  # initialize bag of words\n",
        "  bag = []\n",
        "  # list of tokenized words for the pattern\n",
        "  pattern_words = doc[0]\n",
        "  # Stemming Our Doc Words\n",
        "  __patterns = [stemmer.stem(word.lower()) for word in pattern_words if word not in ignore]\n",
        "  # create bag of words array\n",
        "  for w in words:\n",
        "    bag.append(1) if w in __patterns else bag.append(0)\n",
        "  # output is '1' for current tag and '0' for rest of other tags\n",
        "  output_row = list(output_empty)\n",
        "  # Here i am making target list for fully connected layer in Neural Network\n",
        "  output_row[classes.index(doc[1])] = 1\n",
        "  training.append([bag, output_row])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUZD9L-fs3Hz"
      },
      "source": [
        "#**Theory Behind Bag of Words Approach**\n",
        "\n",
        "To understand the bag of words approach, let's first start with the help of an example.\n",
        "\n",
        "Suppose we have a corpus with three sentences:\n",
        "\n",
        "    \"I like to play football\"\n",
        "    \"Did you go outside to play tennis\"\n",
        "    \"John and I play tennis\"\n",
        "\n",
        "Now if we have to perform text classification, or any other task, on the above data using statistical techniques, we can not do so since statistical techniques work only with numbers. Therefore we need to convert these sentences into numbers.\n",
        "Step 1: Tokenize the Sentences\n",
        "\n",
        "The first step in this regard is to convert the sentences in our corpus into tokens or individual words. Look at the table below:\n",
        "Sentence 1 \tSentence 2 \tSentence 3\n",
        "I \tDid \tJohn\n",
        "like \tyou \tand\n",
        "to \tgo \tI\n",
        "play \toutside \tplay\n",
        "football \tto \ttennis\n",
        "\tplay \t\n",
        "\ttennis \t\n",
        "Step 2: Create a Dictionary of Word Frequency\n",
        "\n",
        "The next step is to create a dictionary that contains all the words in our corpus as keys and the frequency of the occurrence of the words as values. In other words, we need to create a histogram of the words in our corpus. Look at the following table:\n",
        "```\n",
        "Word \tFrequency\n",
        "I \t2\n",
        "like \t1\n",
        "to \t2\n",
        "play \t3\n",
        "football \t1\n",
        "Did \t1\n",
        "you \t1\n",
        "go \t1\n",
        "outside \t1\n",
        "tennis \t2\n",
        "John \t1\n",
        "and \t1\n",
        "```\n",
        "In the table above, you can see each word in our corpus along with its frequency of occurrence. For instance, you can see that since the word play occurs three times in the corpus (once in each sentence) its frequency is 3.\n",
        "\n",
        "In our corpus, we only had three sentences, therefore it is easy for us to create a dictionary that contains all the words. In the real world scenarios, there will be millions of words in the dictionary. Some of the words will have a very small frequency. The words with very small frequency are not very useful, hence such words are removed. One way to remove the words with less frequency is to sort the word frequency dictionary in the decreasing order of the frequency and then filter the words having a frequency higher than a certain threshold.\n",
        "\n",
        "Let's sort our word frequency dictionary:\n",
        "```\n",
        "Word \tFrequency\n",
        "play \t3\n",
        "tennis \t2\n",
        "to \t2\n",
        "I \t2\n",
        "football \t1\n",
        "Did \t1\n",
        "you \t1\n",
        "go \t1\n",
        "outside \t1\n",
        "like \t1\n",
        "John \t1\n",
        "and \t1\n",
        "```\n",
        "Step 3: Creating the Bag of Words Model\n",
        "\n",
        "To create the bag of words model, we need to create a matrix where the columns correspond to the most frequent words in our dictionary where rows correspond to the document or sentences.\n",
        "\n",
        "Suppose we filter the 8 most occurring words from our dictionary. Then the document frequency matrix will look like this:\n",
        "```\n",
        "\tPlay \tTennis \tTo \tI \tFootball \tDid \tYou \tgo\n",
        "Sentence 1 \t1 \t0 \t1 \t1 \t1 \t0 \t0 \t0\n",
        "Sentence 2 \t1 \t1 \t1 \t0 \t0 \t1 \t1 \t1\n",
        "Sentence 3 \t1 \t1 \t0 \t1 \t0 \t0 \t0 \t0\n",
        "```\n",
        "It is important to understand how the above matrix is created. In the above matrix, the first row corresponds to the first sentence. In the first, the word \"play\" occurs once, therefore we added 1 in the first column. The word in the second column is \"Tennis\", it doesn't occur in the first sentence, therefore we added a 0 in the second column for sentence 1. Similarly, in the second sentence, both the words \"Play\" and \"Tennis\" occur once, therefore we added 1 in the first two columns. However, in the fifth column, we add a 0, since the word \"Football\" doesn't occur in the second sentence. In this way, all the cells in the above matrix are filled with either 0 or 1, depending upon the occurrence of the word. Final matrix corresponds to the bag of words model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d-D-iDXsZ5n",
        "outputId": "2ce7058e-d68d-4cd9-98dd-0935173ee9db"
      },
      "source": [
        "# shuffling features and turning it into np.array\n",
        "random.shuffle(training)\n",
        "training = np.array(training)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DPsA6A_tVdJ"
      },
      "source": [
        "# creating training lists\n",
        "train_x = list(training[:,0])\n",
        "train_y = list(training[:,1])"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdbpwHGmtjJZ",
        "outputId": "bb740edf-8e74-4e43-937f-ad2cbaf5baaa"
      },
      "source": [
        "len(train_x[0])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "194"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOt5DbGztm2A",
        "outputId": "43bc983c-afc9-4d4f-9824-f62b2bf347bc"
      },
      "source": [
        "len(train_y[0])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNKo96R9tasp"
      },
      "source": [
        "**Creating Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7i47dV0RtXom",
        "outputId": "007fb431-f3ca-4434-bf27-e1900f6ea7b4"
      },
      "source": [
        "\n",
        "\n",
        "# resetting underlying graph data\n",
        "from tensorflow.python.framework import ops\n",
        "ops.reset_default_graph()\n",
        "\n",
        "# Building neural network\n",
        "net = tflearn.input_data(shape=[None, len(train_x[0])]) # Input Layer and First Hidden Layer\n",
        "net = tflearn.fully_connected(net, len(classes)) # Second Hidden Layer\n",
        "net = tflearn.fully_connected(net, len(classes)) # Third Hidden Layer\n",
        "net = tflearn.fully_connected(net, len(train_y[0]), activation='softmax') # Using Softmax in Output layer because this n eural network have more than 1 outputs\n",
        "net = tflearn.regression(net) #The regression layer is used in TFLearn to apply a regression (linear or logistic) to the provided input.\n",
        "\n",
        "\n",
        "\n",
        "# Defining model and setting up tensorboard (Deep Neural Network Model)\n",
        "model = tflearn.DNN(net, tensorboard_dir='tflearn_logs')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/initializations.py:165: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xc398F9tudU8"
      },
      "source": [
        "**Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtBFIMZjuM43",
        "outputId": "e74154e0-6592-436d-a137-3db4968e1dbd"
      },
      "source": [
        "# Start training\n",
        "model.fit(train_x, train_y, n_epoch=1000, batch_size=8, show_metric=True)\n",
        "model.save('chatbot.tflearn')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Step: 5999  | total loss: \u001b[1m\u001b[32m0.40214\u001b[0m\u001b[0m | time: 0.030s\n",
            "| Adam | epoch: 1000 | loss: 0.40214 - acc: 0.8422 -- iter: 40/47\n",
            "Training Step: 6000  | total loss: \u001b[1m\u001b[32m0.37906\u001b[0m\u001b[0m | time: 0.035s\n",
            "| Adam | epoch: 1000 | loss: 0.37906 - acc: 0.8437 -- iter: 47/47\n",
            "--\n",
            "INFO:tensorflow:/content/chatbot.tflearn is not in all_model_checkpoint_paths. Manually adding it.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbDVBTMSulvW"
      },
      "source": [
        "# Let's Save our Model Structures\n",
        "import pickle\n",
        "with open( \"training_data\", \"wb\" ) as file:\n",
        "  pickle.dump( {'words':words, 'classes':classes, 'train_x':train_x, 'train_y':train_y}\n",
        "               , file)\n",
        "file.close()"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pn87MQqOxgA_"
      },
      "source": [
        "**Test Our Bot**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbSmTqUexbO3"
      },
      "source": [
        "# restoring all the data structures\n",
        "with open( \"training_data\", \"rb\" ) as file:\n",
        "  data = pickle.load(file)\n",
        "  words = data['words']\n",
        "  classes = data['classes']\n",
        "  train_x = data['train_x']\n",
        "  train_y = data['train_y']\n",
        "file.close()"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcxi9dETx3A1"
      },
      "source": [
        "with open('intents.json') as json_data:\n",
        "    intents = json.load(json_data)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12EgiCiex8mH",
        "outputId": "d21f0c2b-4f62-43f2-f5c4-6ff6c28554c0"
      },
      "source": [
        "# load the saved model\n",
        "model.load('./chatbot.tflearn')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/chatbot.tflearn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzIVwaqCx_Ko"
      },
      "source": [
        "def clean_up_sentence(sentence):\n",
        "  # tokenizing the pattern\n",
        "  sentence_words = nltk.word_tokenize(sentence)\n",
        "  # stemming each word\n",
        "  __sentence = []\n",
        "  for word in sentence_words:\n",
        "    __sentence.append(stemmer.stem(word.lower()))\n",
        "  return __sentence"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaz0Kb_VyPWV",
        "outputId": "f4162bd6-3417-467e-8046-2c6cb83d7a8e"
      },
      "source": [
        "clean_up_sentence(\"HI How Are You\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hi', 'how', 'ar', 'you']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sO_dy3d1yRd1"
      },
      "source": [
        "# returning bag of words array: 0 or 1 for each word in the bag that exists in the sentence\n",
        "def bow(sentence, words, show_details=False):\n",
        "    # tokenizing the pattern\n",
        "    sentence_words = clean_up_sentence(sentence)\n",
        "    # generating bag of words\n",
        "    bag = [0]*len(words)  \n",
        "    for s in sentence_words:\n",
        "        for idx,wrd in enumerate(words):\n",
        "            if wrd == s: \n",
        "                bag[idx] = 1\n",
        "                if show_details:\n",
        "                    print (\"found in bag: %s\" % wrd)\n",
        "\n",
        "    return(np.array(bag))"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXouVV_-ymKz"
      },
      "source": [
        "# Error Threshold means chatbot only reply if less than threshold\n",
        "ERROR_THRESHOLD = 0.30"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFnWmO_Tyx21"
      },
      "source": [
        "ERROR_THRESHOLD = 0.30\n",
        "def classify(sentence):\n",
        "    # generate probabilities from the model\n",
        "    results = model.predict([bow(sentence, words)])[0]\n",
        "    # filter out predictions below a threshold\n",
        "    __result = []\n",
        "    for idx, r in enumerate(results):\n",
        "      if r > ERROR_THRESHOLD:\n",
        "        __result.append([idx, r])\n",
        "    # sort by strength of probability\n",
        "    __result.sort(key=lambda value: value[1], reverse=True)\n",
        "    __pred = []\n",
        "    for val in __result:\n",
        "        __pred.append((classes[val[0]], val[1]))\n",
        "    # return tuple of intent and probability\n",
        "    return __pred"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-u11Q5Zy-rl",
        "outputId": "b6bd8ec5-6d76-4af3-f10e-89fba717a402"
      },
      "source": [
        "classify(\"How are you\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('goodbye', 0.35115057), ('thanks', 0.32552552), ('greeting', 0.31122264)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHdoHr4LzBcT",
        "outputId": "86fcb1ca-039c-48b2-90d1-e78294791426"
      },
      "source": [
        "classify(\"Thanks\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('greeting', 0.54171276)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzEClI9czmjg"
      },
      "source": [
        "def response(sentence, userID='123', show_details=False):\n",
        "  __result = classify(sentence)\n",
        "    # if we have a classification then find the matching intent tag\n",
        "  if __result:\n",
        "  # loop as long as there are matches to process\n",
        "    while __result:\n",
        "      for i in intents['intents']:\n",
        "        # find a tag matching the first result\n",
        "        if i['tag'] == __result[0][0]:\n",
        "          # a random response from the intent\n",
        "          __bot_response = random.choice(i['responses'])\n",
        "          return __bot_response\n",
        "      __result.pop(0)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XYBMSUOS0cOF",
        "outputId": "1f9fce1e-eef0-4777-c9b7-e814f7939bb2"
      },
      "source": [
        "response(\"Thanks\")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Hello, thanks for asking'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QFWGAIUW0esR",
        "outputId": "3387cbed-cfcc-417a-cb1c-b16ddf1f11fc"
      },
      "source": [
        "# Let's Check line from training data\n",
        "response(\"How are you\", show_details=True)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"We're open every day 9am-9pm\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCos4C0W33bl"
      },
      "source": [
        "#**Adding Context Feature in Order to Save bot from wandering**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KZQTfYF1Q5d"
      },
      "source": [
        "#Adding some context to the conversation i.e. Contexualization for altering question and intents etc.\n",
        "# create a data structure to hold user context\n",
        "context = {}\n",
        "\n",
        "ERROR_THRESHOLD = 0.25\n",
        "def classify(sentence):\n",
        "    # generate probabilities from the model\n",
        "    results = model.predict([bow(sentence, words)])[0]\n",
        "    # filter out predictions below a threshold\n",
        "    __result = []\n",
        "    for idx, r in enumerate(results):\n",
        "      if r > ERROR_THRESHOLD:\n",
        "        __result.append([idx, r])\n",
        "    # sort by strength of probability\n",
        "    __result.sort(key=lambda value: value[1], reverse=True)\n",
        "    __pred = []\n",
        "    for val in __result:\n",
        "        __pred.append((classes[val[0]], val[1]))\n",
        "    # return tuple of intent and probability\n",
        "    return __pred\n",
        "  \n",
        "def response(sentence, auth='123', show_details=False):\n",
        "  __result = classify(sentence)\n",
        "    # if we have a classification then find the matching intent tag\n",
        "  if __result:\n",
        "  # loop as long as there are matches to process\n",
        "    while __result:\n",
        "      for i in intents['intents']:\n",
        "        # find a tag matching the first result\n",
        "        if i['tag'] == __result[0][0]:\n",
        "          if \"context\" in i:\n",
        "            if show_details:\n",
        "              print(\"Context:\", i['context'])\n",
        "            context[auth] = i['context']\n",
        "          if (not 'context_filter' in i) or (auth in context) and ('context_filter' in i) and (i['context_filter'] == context[auth]):\n",
        "            if show_details:\n",
        "              print(\"Tag:\", i['tag'])\n",
        "              # a random response from the intent\n",
        "              __bot_response = random.choice(i['responses'])\n",
        "              return __bot_response\n",
        "      __result.pop(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGyc8vIo5wVt"
      },
      "source": [
        "# Let's Check line from training data\n",
        "response(\"Thanks\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vg4Q8RqS6zzC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}